T[2]
/sum(T)
sum(T)
T[2]/sum(T)
T[1]/sum(T)
CARTb = rpart(isB ~ . - letter, data=train, method="class")
CARTb = rpart(isB ~ . - letter, data=Train, method="class")
prp(CARTb)
CARTb = rpart(isB ~ . - letter, data=Train, cp=0)
prp(CARTb)
CARTb = rpart(isB ~ . - letter, data=Train, cp=0.05)
prp(CARTb)
CARTb = rpart(isB ~ . - letter, data=Train, cp=0.0)
prp(CARTb)
CARTb = rpart(isB ~ . - letter, data=Train, method="class")
prp(CARTb)
CARTb = rpart(isB ~ . - letter, data=Train)
prp(CARTb)
CARTb = rpart(isB ~ . - letter, data=Train, method="class")
prp(CARTb)
CARTb = rpart(isB ~ . - letter, data=Test, method="class")
prp(CARTb)
CARTb = rpart(isB ~ . - letter, data=Train, method="class")
prp(CARTb)
# Make predictions
PredictTest = predict(CARTb, newdata = Test, type = "class")
table(letters$isB, PredictTest)
table(Test$isB, PredictTest)
T = table(Test$isB, PredictTest)
T
# accuracy
sum(diag(T))/sum(T)
Forest = randomForest(isB ~. - letter, data = Train)
library(randomForest)
Forest = randomForest(isB ~. - letter, data = Train)
PredictForest = predict(Forest, newdata = Test)
table(Test$isB, PredictForest)
T = table(Test$isB, PredictForest)
T
# accuracy
sum(diag(T))/sum(T)
T = table(Test$isB, PredictTest)
T
# accuracy
sum(diag(T))/sum(T)
letters$letter = as.factor( letters$letter )
head(letters)
str(letters)
set.seed(2000)
spl = sample.split(letters$isB, SplitRatio = 0.5)
Train = subset(letters, spl==TRUE)
Test = subset(letters, spl==FALSE)
T = table(Test$isB)
T
T[1]/sum(T)
letters = read.csv("letters_ABPR.csv")
letters$isB = as.factor(letters$letter == "B")
set.seed(1000)
spl = sample.split(letters$isB, SplitRatio = 0.5)
Train = subset(letters, spl==TRUE)
Test = subset(letters, spl==FALSE)
T = table(Test$isB)
T
T[1]/sum(T)
set.seed(2000)
spl = sample.split(letters$isB, SplitRatio = 0.5)
Train = subset(letters, spl==TRUE)
Test = subset(letters, spl==FALSE)
T = table(Test$isB)
T
T[1]/sum(T)
head(letters)
str(letters)
str(letters)
letters$letter = as.factor( letters$letter )
head(letters)
str(letters)
spl = sample.split(letters$letter, SplitRatio = 0.5)
Train = subset(letters, spl==TRUE)
Test = subset(letters, spl==FALSE)
T = table(Test$isB)
T
T[1]/sum(T)
T = table(Test$letter)
T
T[1]/sum(T)
set.seed(1000)
spl = sample.split(letters$isB, SplitRatio = 0.5)
Train = subset(letters, spl==TRUE)
Test = subset(letters, spl==FALSE)
T = table(Test$isB)
T
T[1]/sum(T)
T = table(Test$letter,Test$isB)
T = table(Test$isB)
T
T[1]/sum(T)
table(Train$isB)
T
letters = read.csv("letters_ABPR.csv")
head(letters)
str(letters)
letters$letter = as.factor( letters$letter )
head(letters)
str(letters)
set.seed(2000)
spl = sample.split(letters$letter, SplitRatio = 0.5)
Train = subset(letters, spl==TRUE)
Test = subset(letters, spl==FALSE)
T = table(Test$letter)
T
T[3]/sum(T)
letters$isB = as.factor(letters$letter == "B")
head(letters)
letters$letter = as.factor( letters$letter )
head(letters)
str(letters)
set.seed(2000)
spl = sample.split(letters$letter, SplitRatio = 0.5)
Train = subset(letters, spl==TRUE)
Test = subset(letters, spl==FALSE)
T = table(Test$letter)
T
T[3]/sum(T)
CARTletter = rpart(letter ~ . - isB, data=Train, method="class")
prp(CARTlatter)
prp(CARTletter)
# Make predictions
PredictTest = predict(CARTletter, newdata = Test, type = "class")
T = table(Test$letter, PredictTest)
T
# accuracy
sum(diag(T))/sum(T)
# Build random forest model
set.seed(1000)
Forest = randomForest(letter ~. - isB, data = Train)
# Make predictions
PredictForest = predict(Forest, newdata = Test)
T = table(Test$letter, PredictForest)
T
# accuracy
sum(diag(T))/sum(T)
setwd("G:/Dropbox (SSML)/SHARE_Programming/R/The Analytics Edge/UNIT 4/HW_Predicting Earnings from Census Data")
census = read.csv("census.csv")
census = read.csv("census.csv")
str(census)
summary(census)
head(census)
str(census)
set.seed(2000)
spl = sample.split(census$over50k, SplitRatio = 0.6)
Train = subset(census, spl==TRUE)
Test = subset(census, spl==FALSE)
m1 = glm(over50k ~. , data = census, family = binomial)
summary(m1)
m1 = glm(over50k ~. , data = Train, family = binomial)
install.packages(varhandle)
install.packages("varhandle")
library(varhandle)
install.packages("varhandle")
library(varhandle)
census.nonf = unfactor(census)
str(census.nonf)
m1 = glm(over50k ~. , data = Train, family = binomial)
spl = sample.split(census$over50k, SplitRatio = 0.6)
Train = subset(census, spl==TRUE)
Test = subset(census, spl==FALSE)
m1 = glm(over50k ~. , data = Train, family = binomial)
summary(m1)
census = read.csv("census.csv")
set.seed(2000)
spl = sample.split(census$over50k, SplitRatio = 0.6)
Train = subset(census, spl==TRUE)
Test = subset(census, spl==FALSE)
m1 = glm(over50k ~. , data = Train, family = binomial)
summary(m1)
str(census)
m1 = glm(over50k ~ workclass, data = Train, family = binomial)
summary(m1)
census.nonf = unfactor(census)
str(census.nonf)
spl = sample.split(census.nonf$over50k, SplitRatio = 0.6)
Train.nonf = subset(census.nonf, spl==TRUE)
Test.nonf = subset(census.nonf, spl==FALSE)
m2 = glm(over50k ~. , data = Train.nonf, family = binomial)
str(census.nonf)
str(census)
m1 = glm(over50k ~. , data = Train, family = "binomial")
summary(m1)
# AUC
library(ROCR)
# glm prediction
predTest = predict(m1, newdata = Test, type="response")
# ROC prediction
ROCRpredTest = prediction(predTest, Test$over50k)
# AUC for ROC
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
auc
T = table(Test$over50k, pred >= 0.5)
T
T = table(Test$over50k, predTest >= 0.5)
T
# accuracy
sum(diag(T))/sum(T)
# baseline accuracy
base = table(census$over50k)
base[1]/sum(base)
base
# baseline accuracy
base = table(Test$over50k)
base
base[1]/sum(base)
# ROC prediction
ROCRpredTest = prediction(predTest, Test$over50k)
# AUC for ROC
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
auc
CART = rpart(over50k ~ . - letter, data=Train, method="class")
prp(CARTb)
CART = rpart(over50k ~ ., data=Train, method="class")
prp(CARTb)
prp(CART)
CART = rpart(over50k ~ ., data=Train)
prp(CART)
CART = rpart(over50k ~ ., data=Train, method="class")
prp(CART)
# Make predictions
PredictTest = predict(CART, newdata = Test, type = "class")
T = table(Test$over50k, PredictTest)
T
# accuracy
sum(diag(T))/sum(T)
# glm prediction
PredTest.glm = predict(m1, newdata = Test, type="response")
T = table(Test$over50k, PredTest.glm >= 0.5)
T
# glm accuracy
sum(diag(T))/sum(T)
# baseline accuracy
base = table(Test$over50k)
base
base[1]/sum(base)
# ROC prediction
ROCRpredTest = prediction(PredTest.glm, Test$over50k)
# AUC for ROC
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
auc
# Make predictions
PredTest.cart = predict(CART, newdata = Test, type = "class")
T = table(Test$over50k, PredictTest)
T = table(Test$over50k, PredTest.cart)
T
# accuracy
sum(diag(T))/sum(T)
# ROC prediction
ROCRpredTest = prediction(PredTest.cart, Test$over50k)
CART = rpart(over50k ~ ., data=Train)
prp(CART)
# ROC prediction
ROCRpredTest = prediction(PredTest.cart, Test$over50k)
CART = rpart(over50k ~ ., data=Train, method="class")
prp(CART)
# Make predictions
PredTest.cart = predict(CART, newdata = Test)
# ROC prediction
ROCRpredTest = prediction(PredTest.cart, Test$over50k)
# ROC prediction
ROCRpredTest = prediction(PredTest.cart, Test$over50k)
# Make predictions
PredTest.cart = predict(CART, newdata = Test, type = "class")
# ROC prediction
ROCRpredTest = prediction(PredTest.cart, Test$over50k)
CART = rpart(over50k ~ ., data=Train, method="class")
prp(CART)
# Make predictions
PredTest.cart = predict(CART, newdata = Test, type = "class")
T = table(Test$over50k, PredTest.cart)
T
# accuracy
sum(diag(T))/sum(T)
PredictROC = predict(CART, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$over50k)
perf = performance(pred, "tpr", "fpr")
plot(perf)
pred = prediction(PredTest.glm[,2], Test$over50k)
pred = prediction(PredTest.glm[,1], Test$over50k)
predict.glm()
predict.glm
PredTest.glm[,2]
PredTest.glm
PredTest.glm[2,]
PredTest.glm[1,]
PredTest.glm[1]
PredTest.glm[1,1]
PredTest.glm[1,]
PredTest.glm[1,:]
PredictROC
pred = prediction(PredTest.glm, Test$over50k)
perf = performance(pred, "tpr", "fpr")
plot(perf)
PredictROC = predict(CART, newdata = Test, type = "class")
PredictROC
# ROC for cart
pred = prediction(PredictROC[,2], Test$over50k)
# remove type="class" to evaluate probability
PredictROC = predict(CART, newdata = Test)
# ROC for cart
pred = prediction(PredictROC[,2], Test$over50k)
perf = performance(pred, "tpr", "fpr")
plot(perf)
# ROC for glm
pred = prediction(PredTest.glm, Test$over50k)
perf = performance(pred, "tpr", "fpr")
plot(perf)
# AUC for ROC
auc = as.numeric(performance(PredictROC, "auc")@y.values)
auc
# remove type="class" to evaluate probability
PredictROC = predict(CART, newdata = Test)
# AUC for ROC
auc = as.numeric(performance(PredictROC, "auc")@y.values)
# ROC for cart
pred = prediction(PredictROC[,2], Test$over50k)
perf = performance(pred, "tpr", "fpr")
# AUC for ROC
auc = as.numeric(performance(Pred, "auc")@y.values)
auc
# AUC for ROC
auc = as.numeric(performance(pred, "auc")@y.values)
auc
set.seed(1)
trainSmall = train[sample(nrow(train), 2000), ]
trainSmall = train[sample(nrow(Train), 2000), ]
trainSmall = Train[sample(nrow(Train), 2000), ]
# Build random forest model
Forest = randomForest(over50k ~. , data = trainSmall)
# Make predictions
PredictForest = predict(Forest, newdata = Test)
T = table(Test$over50k, PredictForest)
T
# accuracy
sum(diag(T))/sum(T)
MODEL = Forest
vu = varUsed(MODEL, count=TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(MODEL$forest$xlevels[vusorted$ix]))
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(MODEL$forest$xlevels[vusorted$ix]))
dotchart(vusorted$x, names(MODEL$forest$xlevels[vusorted$ix]))
varImpPlot(MODEL)
dotchart(vusorted$x, names(MODEL$forest$xlevels[vusorted$ix]))
varImpPlot(MODEL)
cartGrid = expand.grid( .cp = seq(0.002,0.1,0.002))
# What did we just do?
1*0.001
10*0.001
0:10
0:10 * 0.001
# Number of folds
tr.control = trainControl(method = "cv", number = 10)
# Load libraries for cross-validation
library(caret)
library(e1071)
set.seed(2)
cartGrid = expand.grid( .cp = seq(0.002,0.1,0.002))
# Number of folds
tr.control = trainControl(method = "cv", number = 10)
# cp values
set.seed(2)
cartGrid = expand.grid( .cp = seq(0.002,0.1,0.002))
# Cross-validation
tr = train(over50k~. , data = Train, method = "rpart", trControl = tr.control, tuneGrid = cartGrid)
# Extract tree
best.tree = tr$finalModel
prp(best.tree)
tr
# Make predictions
best.tree.pred = predict(best.tree, newdata=Test)
# Make predictions
best.tree.pred = predict(best.tree, newdata=Test)
# Extract tree
best.tree = tr$finalModel
prp(best.tree)
PredictROC = predict(CART, newdata = Test)
PredictROC
# run CART model again
CART = rpart(over50k ~ . , data=Train, cp=0.002)
prp(CART)
# Make predictions
PredictTest = predict(CART, newdata = Test, type = "class")
T = table(Test$isB, PredictTest)
T = table(Test$over50k, PredictTest)
T
# accuracy
sum(diag(T))/sum(T)
CART = rpart(over50k ~ ., data=Train, method="class")
prp(CART)
# Make predictions
PredTest.cart = predict(CART, newdata = Test, type = "class")
T = table(Test$over50k, PredTest.cart)
T
# accuracy
sum(diag(T))/sum(T)
# ROC curve
library(ROCR)
# remove type="class" to evaluate probability
PredictROC = predict(CART, newdata = Test)
# Extract tree
best.tree = tr$finalModel
prp(best.tree)
summary(best.tree)
# Extract tree
best.tree = tr$finalModel
prp(best.tree)
best.tree.sse = sum((best.tree.pred - test$MEDV)^2)
# Make predictions
best.tree.pred = predict(best.tree, newdata=Test)
prp(CART)
CART = rpart(over50k ~ ., data=Train, method="class")
prp(CART)
# run CART model again
CART = rpart(over50k ~ . , data=Train, cp=0.002)
prp(CART)
setwd("G:/Dropbox (SSML)/SHARE_Programming/R/The Analytics Edge/UNIT 5/LEC_Twitter")
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
str(tweets)
str(tweets)
tweets$Negative = as.factor(tweets$Avg <= -1)
str(tweets)
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
str(tweets)
tweets$Negative = as.factor(tweets$Avg <= -1)
str(tweets)
table(tweets$Negative)
library(tm)
install.packages("tm")
library(tm)
install.packages("SnowballC")
library(SnowballC)
# Create corpus
corpus = VCorpus(VectorSource(tweets$Tweet))
# Look at corpus
corpus
corpus[[1]]$content
corpus = tm_map(corpus, content_transformer(tolower))
corpus[[1]]$content
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]$content
# Look at stop words
stopwords("english")[1:10]
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus[[1]]$content
corpus = tm_map(corpus, stemDocument)
corpus[[1]]$content
head(tweets)
frequencies = DocumentTermMatrix(corpus)
frequencies
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
findFreqTerms(frequencies, lowfreq=200)
findFreqTerms(frequencies, lowfreq=20)
findFreqTerms(frequencies, lowfreq=2000)
findFreqTerms(frequencies, lowfreq=2)
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.995)
sparse
tweetsSparse = as.data.frame(as.matrix(sparse))
str(tweetsSparse)
head(tweetsSparse)
colnames(tweetsSparse) = make.names(colnames(tweetsSparse))
head(tweetsSparse)
tweetsSparse$Negative = tweets$Negative
library(caTools)
set.seed(123)
split = sample.split(tweetsSparse$Negative, SplitRatio = 0.7)
trainSparse = subset(tweetsSparse, split==TRUE)
testSparse = subset(tweetsSparse, split==FALSE)
findFreqTerms(frequencies, lowfreq=100)
library(rpart)
library(rpart.plot)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
prp(tweetCART)
# Evaluate the performance of the model
predictCART = predict(tweetCART, newdata=testSparse, type="class")
table(testSparse$Negative, predictCART)
(294+18)/(294+6+37+18)
table(testSparse$Negative)
300/(300+55)
library(randomForest)
set.seed(123)
tweetRF = randomForest(Negative ~ ., data=trainSparse)
# Make predictions:
predictRF = predict(tweetRF, newdata=testSparse)
table(testSparse$Negative, predictRF)
# Accuracy:
(293+21)/(293+7+34+21)
head(trainSparse)
head(trainSparse$Negative)
m1 = glm(Negative ~. , data = trainSparse, family = binomial)
summary(m1)
predictions = predict(tweetLog, newdata=testSparse, type="response")
tweetLog = glm(Negative ~. , data = trainSparse, family = binomial)
summary(tweetLog)
predictions = predict(tweetLog, newdata=testSparse, type="response")
table(testSparse$Negative, predictions)
table(testSparse$Negative, predictions >= 0.2)
table(testSparse$Negative, predictions >= 0.5)
# confusion matrix
T = table(testSparse$Negative, predictions >= 0.5)
T
sum(diag(T))/sum(T)
